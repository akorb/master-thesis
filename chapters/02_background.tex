% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Background}\label{chapter:background}

This chapter discusses the relevant background knowledge required to understand the remainder of this work.

\section{Trusted execution environment}

% Motiviation for TEE's

One of the core security concepts of operating systems are the privilege levels of processes~\cite{Linden1976}. Thereby, processes are protected against other processes with the same or lower privilege level. However, they are not protected against more privileged processes~\cite{Bratus2009}. This bears problems for example for cloud computing and edge computing. In cloud computing, other services, the hypervisor, or the cloud provider could potentially access sensitive data of the cloud tenant~\cite{Nimgaonkar2012}. In edge computing, the edge applications deal with plaintext data, while they are potentially running on insecure edge devices~\cite{Ning2018}. Hence, protection against more privileged processes is desired.


% What TEE's are

The \ac{TEE} is a technology defined by GlobalPlatform\footnote{\url{https://globalplatform.org/}} as an integrated hardware extension to processors. By that, the execution environment is separated into the \ac{REE} and the \ac{TEE} by hardware.
The \ac{REE} runs commodity software, e.g., a Linux-based operating system with user applications.
The \ac{TEE} is an isolated tamper-resistant execution environment that guarantees the authenticity of the executed code, and the integrity of runtime states, e.g., memory~\cite{Sabt2015}.
Since a \ac{TEE} is integrated into the processor, there is no separate chip required.
% The TEE allows code to be executed and memory separately to be used on a device in a hardware-protected manner that ensures a high level of confidentiality and integrity.
Moreover, the \ac{TEE} commonly follows the same user and kernel space separation as a rich OS\@. The kernel space is running a trusted OS, and the user space is running the trusted applications~(TAs). 
It focuses on resisting software-based attacks generated in the \ac{REE}, however, also protects against some hardware attacks~\cite{GPSysArch}.


% Differences to previous technologies

Previous, mostly software-based technologies ensure confidentiality and integrity protection of data-in-transit and data-at-rest~\cite{Pecholt2022}, while a \ac{TEE} additionally protects data-in-use in hardware~\cite{Pecholt2022, Lee:EECS-2022-96}.
% For example, smart cards are commonly used to store keys to identify users and to encrypt data-at-rest~\cite{Arthur2015}.

% Figure explanation

\autoref{fig:tee_motivation} illustrates the motivation of a \ac{TEE}\@.
In the traditional architecture, i.e., without a \ac{TEE}, if an attacker compromises the \ac{REE} the full system is affected.
With a \ac{TEE}, the attacker is limited to the \ac{REE}, while the \ac{TEE} continues to protect the secure assets, such as encryption keys.
This results from the observation that the attack surface of a rich OS is much larger than that of a trusted OS, e.g., due to its network connectivity and the high dynamics of software installations, while the attack surface of a trusted OS is rather small and has tightly controlled interfaces.

\input{elements/figure_tee_motivation.tex}

% \subsection{Arm TrustZone}

\paragraph{Arm TrustZone}
One such \ac{TEE} is Arm's TrustZone~\cite{ARM09, Ngabonziza2016}. It partitions all software and hardware resources of the containing system into the \ac{NW} and the \ac{SW}, as shown in \autoref{fig:arm_trustzone_arch}. The secure monitor is triggered by the dedicated instruction Secure Monitor Call (SMC), which then manages the context switches between the \ac{NW} and the \ac{SW}.
While the \ac{SW} can access the resources of the \ac{SW} and the \ac{NW}, the \ac{NW} is restricted to its own assigned resources.
Since Arm is the dominant processor architecture for Internet of Things (IoT) devices with a market share of 86\,\% as of 2022~\cite{eclipse}, many of the approaches in this field of research use Arm TrustZone~\cite{Valadares2021}.
% Our implementation also leverages TrustZone to enable the execution and the remote attestation of an fTPM\@.

% However, our design is not limited to Arm TrustZone.
Other \ac{TEE} technologies are Intel Software Guard Extensions~(SGX), and AMD Secure Encrypted Virtualization~(SEV), in the future also Intel Trusted Domain Extensions~(TDX), and Arm Confidential Computing Architecture~(CCA).

\input{elements/figure_arm_trustzone_arch.tex}

% \subsection{Further TEE technologies}


% However, our concept is not tied to Arm processors and can also be applied to these others, and are mentioned for the sake of completeness.

% TrustZone, Trusted applications are not isolated -> they need to trust each other

% From TrustZone section in TPM book: Peripherals can be switched between the NW and SW by configuring the system monitor to forward the peripheral interrupts only to the assigned world, because some peripherals might need to be secure only temporarily.

% static: Arm TZ
% dynamic: Intel SGX, TDX, AMD SEV


\section{Remote Attestation}

% According to the Cambridge Dictionary an attestation is ``a formal statement that you make and officially say is true''.

According to NIST SP 1800--19B~\cite{Bartock2022} an attestation is ``the process of providing a digital signature for a set of measurements securely stored in hardware, and then having the requester validate the signature and the set of measurements.''
% Specifically in our context, remote attestation is a mechanism for a prover 
% In the following, the two types are discussed.


% \subsection{Local attestation}

% To TPM use-cases
% Local attestation is a procedure in which the state of a computer is measured, whereby the measurement result does not leave the computer but is used directly by a local component. One such example is a \ac{TPM} that releases data, e.g., an encryption key, only when the computer is in a known state. This feature is known as sealing~\cite{tpm20}.

% Local attestation enables assertions between two environments on the same system~\cite{Anati2013InnovativeTF}. The claim of an environment can be verified by another environment, usually with the help of message authentication codes (MAC)~\cite{Menetrey2022}. For example, Intel SGX uses this mechanism to establish assertions between two enclaves~\cite{Anati2013InnovativeTF}.

% \subsection{Remote attestation}

% Doctor analogy
% A company conducts a remote attestation if a worker provides a sickness attest to a company.
% In this scenario, the worker is the attester/prover, the doctor is the verifier, and the company is the relying party.
% Trust in the doctor is established via his medical license, rooted most commonly in a government agency who only certifies doctors which are declared trustworthy since they fulfilled a list of requirements, like succeeding a medical education. 

\input{elements/figure_remote_attestation.tex}

% It provides the ability for a prover to prove its software's identity to a remote party, i.e., the verifier.
Remote attestation is a challenge-response protocol initiated by a remote party---the verifier---to verify that a target environment, i.e., the attested system, on the end-device---the prover---has not been tampered with~\cite{Menetrey2022, Coker2011}.
\autoref{fig:ra} depicts a simplified overview of its data flow.

In a typical remote attestation procedure, the attester measures the attested system during its boot process.
A verifier initiates the remote attestation protocol by sending a challenge with a nonce to the prover.
The prover then signs the measurement data combined with the nonce, with the final data structure usually referred to as the evidence.
The nonce forces a fresh response and thus prevents replay attacks on the evidence.
The evidence is then transmitted to the remote verifier, where it is evaluated.

% The response must be an evidence of the challenged system that it is trustworthy.
% To build that, an attesting environment on the prover device generally inspects the following properties of a program: (i) its code and data has been correctly loaded into memory for execution, and (ii) its data has not been maliciously modified at runtime.

The attester acts here as the \ac{RTM} for the verifier.
Most importantly, it must be isolated from the attested system such that it cannot be compromised by it.
The verifier establishes trust to the attester by getting to know its manufacturer and the security properties that they guarantee.
Consequently, the verifier can trust the statements the attester conducts about the attested system.
% It is required because the verifier requires a trusted component on the prover's system whose statements it can trust.
% Typically, the \ac{RTM} runs within the \ac{TEE}, as this isolates it from the target environment to be attested.

Remote attestation commonly consists of two steps~\cite{McCune2008}.
(i) The attestation, and (ii) the accompanying establishment of a secure channel.
In this work, we focus on the first step.

A remote attestation procedure can further be divided into two categories---implicit and explicit attestation~\cite{dice-layering-arch}.
In implicit attestation, the state of the prover is implicitly inferred from the fact that it has control over a signing key that is only accessible if the prover is in a known state.
That is, the sole ability to create the evidence defines the properties of trustworthiness.
With explicit attestation, the state of the device is explicitly described in the evidence.
The solution we propose carries out an explicit attestation.

\section{Trusted Platform Module}\label{sec:tpm}

The \ac{TCG}\footnote{\url{https://trustedcomputinggroup.org/}} published the first TPM specification (v1.1) in August 2000~\cite{tpm11}, and the most current specification to date (v2.0 Revision 01.59) 19 years later in November 2019~\cite{tpm20}.
% First v2.0 version was much earlier
It describes a cryptographic coprocessor that increases trust in the host platform.
Specifically, this means that the TPM exhibits the expected behavior and that this behavior can be trusted.
For that, the TPM maintains a separate state from the host platform, which enables the TPM to take measurements of the host platform.
It is also a passive device, meaning it only does something when prompted.
\autoref{tab:tpm_use_cases} summarizes the main features of TPMs.

\input{elements/table_tpm_use_cases.tex}

Each key created and stored on a TPM is part of one of four hierarchies.
The following list shows the official names of the hierarchies as defined in the TPM specification~\cite{tpm20}, some alternative names behind them in brackets, as they are sometimes referred to, and the intended use-case of the hierarchies~\cite{Arthur2015}.
\begin{itemize}

  \item{\textbf{Storage hierarchy (owner hierarchy)}\\
  This is the hierarchy mainly used by the end user of a TPM, e.g., to store SSH keys.}

  \item{\textbf{Endorsement hierarchy (privacy hierarchy)}\\
  Therein are stored privacy-sensitive keys, most importantly the EK.}

  \item{\textbf{Platform hierarchy}\\
  It is intended to be used by early boot code like the UEFI\@.
  For example, the UEFI can store its configurations under this hierarchy.}

  \item{\textbf{Null hierarchy (ephemeral hierarchy)}\\
  Used for temporary keys, e.g., when the TPM is being used as a cryptographic coprocessor.
  Keys in this hierarchy are discarded when the TPM is restarted.}

\end{itemize}


The hierarchies are separated in order to provide actors with finely granular access to the TPM\@.
For example, a privacy administrator can only have access to the endorsement hierarchy, while the end user only has access to the owner hierarchy.
They possess different behaviors as well.
The Null hierarchy, for example, cannot be restricted, while the Platform hierarchy is unlocked each time the TPM is restarted, i.e., has an empty password, and is intended to be locked by the early boot code by setting a password only known to the early boot code.

\input{elements/figure_tpm_hierarchies.tex}

A TPM derives keys from two parameters, a source of object entropy and a key template.
The object entropy for a primary key comes from the according primary seed, for an ordinary key from the parent key, as depicted in \autoref{fig:tpm-hierarchies}.
Note that the number of children and the hierarchy depth in this figure are exemplary and there are no technical restrictions for this in the TPM specification.

A template contains metadata of the key, such as the type of the key like RSA-2048, and the object attributes, for example, whether the key can be used for encryption or signing.
Keys can be \texttt{restricted}, which limits the key to be used with data generated by the TPM~\cite{tpm20}.
For signing keys, this prevents an attacker from asking the TPM to sign an artificially constructed quote.
Analogously, restricted encryption keys can only be used to encrypt data generated by the TPM, e.g., other keys created on the TPM\@.

% \autoref{eq:ek}.
% \begin{equation}
%     \label{eq:ek}
%     key = KDF(entropy\_source,\ key_{template})
% \end{equation}

The \acp{PCR} are the fundament for the remote system attestation.
They are one-way registers, which values can never be written explicitly, but only be extended; this operation is known as \emph{hash extend}~\cite{Arthur2015}.
Its design prohibits the removal of extensions, which would cause the TPM to forget a measurement, and the arbitrary writing of values, which would overwrite any previously conducted measurements.
A PCR value holds a hash representing the platform state.
Thereby, a remote verifier can request a so-called \emph{quote} from the TPM on the host in question.
A quote contains the hash of all requested PCR values and is digitally signed.
Typically, a TPM~2.0 contains 24 PCR registers, as defined as the minimum by~\cite{tcgPcClientTpmProfile}, with the first eight representing the firmware boot process and the higher ones representing the OS or applications~\cite{tcgPcClientFirmwareProfile}.
%\autoref{tab:pcr_usages} shows the components each PCR value represents as specified by the TPM PC Client specification~\cite{tcgPcClientFirmwareProfile}.
The fixed length of the \ac{PCR} values is important for the memory-constrained nature of TPMs~\cite{Arthur2015}.

The PCR value at index \(i\) can only be modified, i.e., extended, by adding together the currently contained hash value and the new hash, as depicted in \autoref{eq:pcr_extend}~\cite{tpm20}.
For the sake of correctness, it should be noted that not every PCR is initialized with zero, as stated in the equation.
For example, the TPM PC Client Platform specification~\cite{tcgPcClientTpmProfile} defines that PCRs 1--16, 23 are initialized with all bits set to 0, while PCRs 17--22 are initialized with all bits set to 1.
\begin{equation}
  \label{eq:pcr_extend}
PCR(i)_{t=0} \coloneqq 0,\quad PCR(i)_{t+1} \coloneqq hash(PCR(i)_t\ \Vert\ new\ value)
\end{equation}

%\input{elements/table_pcr_registers}

% Sealing (local attestation)
% EKcert, EK = Unique ID, key in TPM, used for validation
% Binding to TPM (EK)
% Core Root of Trust of Measurement: BIOS extension, trusted hashing
% Attestation: TPM confirms measured state

TPM~1.2 is limited to SHA-1 hashes which are considered broken~\cite{cryptoeprint:2005/010, Wang2005, Stevens2017}.
Although the SHA-1 uses in TPM~1.2 were analyzed to be not affected~\cite{sha1tpm12}, cryptographic algorithms only become weaker over time~\cite{Arthur2015}.
In reaction, TPM~2.0 offers crypto-agility and allows newer algorithms such as SHA-256.
% In general, TPM~2.0 is more flexible, and is always turned on, while a TPM~1.2 needed to be turned on manually.
Also, TPM~2.0 is more consistent across different implementations because of broader specifications.
% Nowadays, TPM~2.0 is the focused version due to its security advantages.
Therefore, Microsoft recommends TPM~2.0 over TPM~1.2~\cite{micrec} due to its security advantages, and also requires TPM~2.0 for Windows~11 with SHA-256 PCR registers~\cite{win11req}.

% SRTM (from the beginning, what we use)
% DRTM (at any point of time, established by HW extensions, root of trust is e.g. Intel microcode/Hardware)

\input{elements/figure_pcr_types}

There are three types of \acp{TPM}---\aclp{dTPM}, \aclp{fTPM}, and virtual TPMs---as illustrated in \autoref{fig:tpm_types}.
They all offer the same functionality, but with different security guarantees and performance characteristics, explained in the following sections.


\subsection{\Acl{dTPM}}

This is the classical form of a TPM\@.
It is a dedicated piece of hardware, connected to the CPU via a bus.
They have their own processor, memory, and storage so that they are completely isolated from the host system and can only be accessed via the bus system.
% It is designed and manufactured to be highly temper-resistant against hardware attacks.
The TPM specifications~\cite{tpm20, tcgPcClientTpmProfile} do not demand a specific bus system, however, they define the interfaces between the TPM and the following bus systems: LPC, I\textsuperscript{2}C, and SPI\@.


\subsection{\Acl{fTPM}}

% Generally more secure? According to https://arxiv.org/pdf/2304.14717.pdf, yes
% But TEEs are also tamper-resistant, aren't they? Maybe not as much as dTPMs.

% https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/msr-tr-2015-84.pdf talks about differences in security

An fTPM~\cite{Raj2015, 197213} is executed directly by the host CPU within a \ac{TEE}.
This isolates it from the \ac{REE}, which means that even the operating system in the REE cannot arbitrarily access the memory of the fTPM\@.
The \ac{REE} can only send commands to the fTPM via controlled interfaces.
These commands are piggybacked by calls from the \ac{REE} to the fTPM in the \ac{TEE}.

The trend is moving towards fTPMs, which can also be seen by the increasing efforts to bring an fTPM to the RISC-V processor family~\cite{Boubakri2021}.
% As of now, a fTPM is strictly bound to the processor manufacturer, such that you can trust the underlying firmware as well which is provisioned by the manufacturer, e.g., Intel, too.
Common implementations are the IntelÂ® Platform Trust Technology~(Intel PTT)~\cite{intelProcessorSecurity}, and AMD's Secure Processor~(AMD-SP), with the latter being an Arm-based coprocessor on the die with TrustZone~\cite{Khalid2020}.

% Disadvantages

Running on the main processor, e.g., a fully-fledged Arm Cortex core, entails advantages and disadvantages.
A disadvantage is that running on the same processor as the rest of the system means less isolation from the remaining system.
% Also, \acp{fTPM} cannot provide true RNG, since hardware is required for that~\cite{Stipcevic2014}.
% Well, they can if the fTPM RNG is connected to a hardware RNG. I think I even remember that in some paper they tried to harden fTPMs just by doing exactly this.
Furthermore, they are started later in the host's boot chain than a \ac{dTPM} that is accessible from the beginning.
Consequently, the measurements of the components booted before the fTPM have to be cached and later forwarded to the \ac{fTPM} once it is available.
Trusted Firmware-A\footnote{\url{https://www.trustedfirmware.org/}}---which is Arm's reference implementation of the boot software in the \ac{TEE}---protects this cached event log by keeping it in secure memory~\cite{tf-a-measured-boot} only accessible by the \ac{TEE}.
Last, fTPMs depend on more components for its security than single-component \acp{dTPM}, e.g., the hardware-provided isolation between the \ac{REE} and the \ac{TEE}, and the boot chain.

% Advantages

However, since they require only a \ac{TEE} which is mostly already available at currently used processors, they are cheaper for manufacturers as they require less extra hardware.
In addition, TPM processors are weak~\cite{Goh2013, Raj2015}.
Raj et al.~\cite{Raj2015} and Cheng et al.~\cite{Cheng2020} independently conclude that firmware TPMs executed on main processors are generally much faster than \acp{dTPM}.
\Acp{fTPM} are also a viable option for adding \ac{TPM} functionality to older devices through software updates rather than hardware replacements, which is particularly valuable in times like the recent chip supply shortage~\cite{Voas2021, casper2021}.


% \begin{table}[htpb]
%   \caption[ftpmdownsides]{Advantages and disadvantages of fTPMs.}\label{tab:tpm_comparison}
%   \centering
%   \begin{tblr}{Q[l,h] Q[l,m]}
%     \toprule
%     Advantages      &  Disadvantages \\
%     \midrule
%     Faster          &  No perfect RNG \\
%     Easier update   &  {Launched later in boot chain.\\ Cannot measure hashes of preceding boot components.} \\
%     \bottomrule
%   \end{tblr}
% \end{table}


\subsection{Virtual TPM}

A vTPM is a software-based TPM provided by a virtual machine manager~(VMM) for one or many of its managed VM's~\cite{268868}.
They can be realized purely in software~\cite{268868}, or backed by dTPMs~\cite{Liu2010}.
% The hypervisor can provide an arbitrary number of vTPMs.
% For the VM's it seems that they have exclusive access to their own private TPM, even though all vTPMs are managed by the same hypervisor.
A characteristic feature of virtual resources are their migration capabilities, i.e., they can be suspended and later continued on another machine.
% Virtual TPMs support this as well.
vTPMs do not inherently have their own security properties as these depend entirely on the vTPM implementation of the hypervisor.


\section{Secure Boot and Measured Boot}

% When the system is started, the first component is executed from ROM\@.
% This subsequently launches the next component, and so forth.
% This boot structure is called the boot chain.
% Typically, the first component turns on the memory, the second stage initializes the platform, and the last stage boots the operating system~\cite{Yao2020}.

Secure Boot~\cite{Hendricks2004, UEFI, Frazelle2020} is a security system that verifies components of the boot chain directly at boot-time.
For that, the system is equipped with a public key that is used to verify the digital signatures of the boot components ensuring their authenticity.
Alternatively, merely the hashes of the components can be measured and compared with benign references values, which only ensures integrity and not authenticity.
The first boot component stored in ROM needs to be trusted without verification, and therefore forms the root of trust.
Nonetheless, Secure Boot does not prevent downgrade attacks, since only the authenticity, but not the concrete versions of boot components are verified~\cite{272306}.
% Hence, further defenses like Measured Boot have been designed.

% Secure Boot is a concept of UEFI~\cite{UEFI, Frazelle2020} doing local attestation of components of the boot chain directly at boot-time. Each stage measures the subsequent component before handing over the execution, and compares it with the expected value. This expected value is signed, i.e., a signature, and each boot binary contains its own signature. Providing a signature verifies not only the integrity, but also the authenticity of the component's source. The boot process is canceled as soon as deviations are detected.
% For this purpose, boot chain binaries are first signed and then, deployed universally. Hence, the binaries are not bound to the platform and can be considered portable in this context.

In contrast, Measured Boot conducts precise measurements of the booted software for retrospective evaluations~\cite{tcgMeasuredBoot}.
This allows a verifier to learn about the exact software booted during a remote attestation process.
It is a concept that is implemented in interplay with a TPM\@.
Just as with Secure Boot, each boot component hashes the subsequent component.
Instead of directly locally verifying the measured value, the hash value is passed to the TPM to extend a \ac{PCR} value.
Consequently, as described in \autoref{sec:tpm}, the TPM can create a quote propagating the state of the measured system.
% The goal is to detect manipulated system configurations.

Secure Boot and Measured Boot are often used in conjunction.

\section{Device Identifier Composition Engine}

% Primer
\Ac{DICE} was originally proposed by Microsoft as part of their Robust IoT (RIoT) architecture~\cite{England2016}.
In 2017, the DICE specification was published by \ac{TCG}~\cite{tcg-microsoft-tpm}, of which Microsoft is a member.
Its purposes are to detect firmware tampering and enable device identification for a remote party, while its main attribute is its low hardware requirements.

% Measurement chain

DICE operates on a boot process layered into components~\cite{dice-layering-arch}.
Each layer must only assume the lower layers to be trustworthy.
Later components typically include more features and are more complex than earlier ones.
Each component is measured prior to being activated by the preceding component.
Great care must be taken to ensure that the identity of the measured and thereafter executed component is consistent to prevent time-of-check to time-of-use attacks (TOCTTOU)~\cite{Hristozov2022, Carpent2018}.
The union of all security-relevant components of a device form its \ac{TCB}.
Their individual identities are called \ac{TCI}, which are usually the hashes of the according firmware binary, but could also consist of a hardware product identifier.
The TCI must also represent security-relevant configurations of a component.
Compilation flag configurations affect the binary file and are therefore inherently included in its TCI\@.
There are also configurations that are not part of the binary usually provided in well-known formats such as \texttt{json} or \texttt{xml}.
They must be measured in conjunction with the corresponding binary file or represented by two separate \acp{TCI}.

% Hardware requirements

% The first component is the DICE itself, which consists of software and hardware.
The DICE layer is the first to be booted.
Its specification~\cite{dice-hardware-reqs} states three hardware requirements.
The DICE layer 
\begin{enumerate}
  \item has to store a read-only \ac{UDS},
  \item has exclusive access to the \ac{UDS},
  \item and is immutable.
\end{enumerate}
These requirements can be justified intuitively.
(1)~The \ac{UDS} must be read-only and unique to the device to provide a basis for long-term identification and derivation of the device's own secrets.
(2)~The DICE layer reads and uses the \ac{UDS}, and then needs to erase the \ac{UDS} from memory while preventing other components from retrieving this secret during the power-on time.
Otherwise, other entities can forge measurement or identification values. This lock mechanism can be realized with eFuses~\cite{dice-hardware-reqs}, for example.
(3)~Moreover, the misbehavior of the DICE layer cannot be detected since it is the root of trust meaning it is not preceded by anything that could measure it.
Therefore, it must be immutable to ensure that it remains in the trusted state in which the manufacturer provided it.

% What is the CDI, and what is it derived from?

While the \ac{UDS} is exclusive to the DICE layer, each later component retrieves a \ac{CDI} from its predecessor.
The \ac{CDI} of each layer depends on two variables combined in a one-way function (OWF).
(i) The own \ac{TCI}, binding the \ac{CDI} to the current layer's identity, i.e., the hash of itself, and (ii) the \ac{CDI} of the previous layer, making each \ac{CDI} depending on the identities of all previous components.
Therefore, if any component is modified, this reflects in the permutation of the \acp{CDI} of all subsequent components, as implied by \autoref{eq:dice_cdi}.

% CDI protection and further uses

Just as the DICE layer must ensure to have exclusive access to the \ac{UDS}, each later layer must ensure no subsequent layer has access to its \ac{CDI}\@.
The layers can derive further secrets using their \ac{CDI} as a seed, such as the Device ID key pair (\autoref{eq:dice_deviceID}) or an alias key pair (\autoref{eq:dice_alias}).

\noindent
\begin{minipage}{\linewidth}
\begin{align}
  \label{eq:dice_cdi}
  CDI_n &= \underbrace{UDS\ \circ\ TCI_0}_{CDI_0}\ \circ\ \ldots\ \circ\ TCI_n\\
  \label{eq:dice_deviceID}
  DeviceID\_KeyPair &= KDF(CDI_0)\\
  \label{eq:dice_alias}
  Alias\_KeyPair_n  &= KDF(CDI_n)
\end{align}
where \(a \circ b = OWF(a,\,b)\), \(\circ\) denotes a left-associated operator, and \(KDF\) is a key derivation function.
\end{minipage}
\vskip0.4\baselineskip

% Certificate chain

The end result of a boot process using \ac{DICE} is a certificate chain, which can be seen in \autoref{fig:dice-layers} and \autoref{eq:cert_chain}.
Here, each certificate represents a layer by embedding the \ac{TCI} of the layer.
The certificate chain is built up progressively during the boot process, with the first two certificates---the manufacturer and DeviceID certificate---being static and stored on the device, and the remaining alias certificates being generated during boot time.
\begin{equation}
  \label{eq:cert_chain}
  Manufacturer\ Cert \rightarrow DeviceID\ Cert \rightarrow Alias\ Cert\ [\rightarrow Alias\ Cert]^*
\end{equation}

The chain's root is the certificate of the DICE manufacturer.
It is either provided by the device or can be retrieved from the manufacturer itself, e.g., via its website, and is typically self-signed.

\input{elements/figure_dice_layers.tex}

% DeviceID certificate

The next certificate is the DeviceID certificate.
It is generated during device provisioning by the manufacturer, and signed by the manufacturer's private key.
This links the DICE implementation to a manufacturer, which is important to retrieve the guarantees the manufacturer conducts for its DICE implementation to protect its \ac{UDS} value, which is the hardware root of trust.
% The DeviceID certificate also contains the TCI of layer~0.
% Hence, during provisioning, the manufacturer must ensure to only sign a DeviceID certificate containing a TCI matching the actual TCI of layer 0.
This certificate also represents the long term identity of the device.
The \ac{UDS} alone cannot be used for this because it is kept strictly secret, whereas the DeviceID certificate is public.
Since the identification relies on asymmetric cryptography, the manufacturer does not need to maintain a database of \ac{UDS} values, but only needs to keep and protect its private key.

% How the trust chain is continued

While the DeviceID's public key is openly stored on the device as part of the DeviceID certificate, the corresponding private key still must be generated during the boot process.
It can only be generated if the identity of layer~0 remains unaltered, which allows the certificate chain to be continued.

% AliasCert

The remaining alias certificates in the chain each represent the identity of a layer.
They contain the measured \ac{TCI} of layer~\( n \) and are signed with the private key of the measuring layer~\( n-1 \).

% The graph

The generation of the \ac{CDI} values and certificates is shown in \autoref{fig:dice-layers}.
There, the \acp{CDI} and certificates are associated with their ultimate usage or the entities they represent, rather than the layer of their creation.
E.g., CDI\textsubscript{\(n\)} and AliasCert\textsubscript{\(n\)} are both created by layer~\( n-1 \), but passed to and used by layer~\( n \).

% How attestation works

For remote attestation, the prover forwards this DICE certificate chain to the verifier.
The verifier must understand the manufacturer part of the DeviceID certificate from DICE and decide whether it is trustworthy.
If this is the case and the signatures of the certificate chain can be verified with the corresponding public keys, the verifier can derive the running software of the prover from the \acp{TCI} part of the certificates.
Finally, they can decide whether this list of \acp{TCI} is trustworthy.

% Security statement

To the best of our knowledge, \ac{DICE} is so far considered secure apart from physical attacks, only implementation problems can bear security problems~\cite{Jaeger2020, Hristozov2022}.
