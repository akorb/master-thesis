% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Discussion}\label{chapter:discussion}

\section{Assessment of the fulfillment of requirements}

\subsection{Security requirements}

\subsection{Attestation process requirements}

% Definitions

\ac{TCG} defines as part of their Trusted Attestation Protocol~\cite{tap} the requirements for an attestation process to provide assurance to a verifier that it is (i) accurate, (ii) interpretable, and (iii) attributable.

(i) Accurate attestation data represents the actual state of the device.
This includes freshness, i.e., the data is not replayed and does not represent an old, outdated state of the device.

(ii) Intuitively, the data must be interpretable by the verifier.
In other words, the verifier must be able to derive a decision about the trustworthiness of the prover based on the attestation data.

(iii) It must be possible to assign the attestation data to a specific device, i.e., it must be verifiable that the attestation data originates from the prover.

% Why they are reached

\section{Higher level protocols' compatibility}

\section{Implications of missing privacy}

% An attacker could use the TCIs to find the exact version of the running software and match this to known vulnerabilities of this version.
% See: https://www.rfc-editor.org/rfc/rfc9334.html#section-11

\section{Hardware knowledge dependency}
% Or hardware-agnostic?

% Comparison to RATS architecture
% For RATS: Our system would be integrated by the verifier to establish trust into the fTPM, the relying party wouldn't need to know about it
% For us: verifier = relying party: full burden, needs to know everything
% but required for a (mostly) independent attestation.
% Otherwise trust relationship between verifier and relying party required
% See also Introduction of https://dl.acm.org/doi/10.1145/3600160.3600171

% See abstract of https://www.ietf.org/archive/id/draft-birkholz-rats-corim-01.html

\section{Hardware requirements DICE + fTPM vs TPM}

% Does it even make sense? (Price wise, maybe energy wise)

\section{Retrieve trustworthy TCIs}

It boils down to whether the verifier can ensure that a specific component does not contain any relevant security holes.
In an ideal scenario, the software manufacturers publicize the TCIs of their software which are considered as secure.
However, as of today, this is not common practice.
% The resulting pool might not be that huge, since there is only a tight spectrum of software fulfilling the purposes of boot firmware.

\subsection{closed source vs. open source}

We expect the verifier to rely on external sources to collect its pool of trustworthy TCIs.
The most prominent example is the observation of CVEs to see if specific versions of a software contain relevant security issues.
For open source software, the verifier has the possibility to derive a security policy based on the source code.

Also, generally speaking, open source software receives more security audits, revealing security holes faster.
With closed source firmware, the verifier is restricted to reverse-engineering (not necessarily doing that itself, e.g., it could also be done by security researchers), or relying on the developer to reliably publicize CVE's about its product.

Usually, this is easier for open source software, which is not a requirement, however.

% The reference values have to come from somebody. Huge burden to the verifier, see paper of Simon for potential improvement

\section{Personal opinion about developed system}

% Maybe too complex?
% Bad feeling about this?
% Benefit bigger than effort?

% https://dl.acm.org/doi/pdf/10.1145/2897937.2898083
% Problems of the prover not being authenticated. This needs to be solved on top of our solution.