% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Discussion}\label{chapter:discussion}

\section{Assessment of the fulfillment of requirements}

\subsection{Security requirements}

\subsection{Attestation process requirements}

% Definitions

\ac{TCG} defines as part of their Trusted Attestation Protocol~\cite{tap} the requirements for an attestation process to provide assurance to a verifier that it is (i) accurate, (ii) interpretable, and (iii) attributable.

\paragraph{Accurate}
Accurate attestation data represents the actual state of the device.
This includes freshness, i.e., the data is not replayed and does not represent an old, outdated state of the device.
While our system ensures this not alone, accuracy is established by the higher level protocol, e.g., retrieving a quote, as long as a nonce is involved.

\paragraph{Interpretable}
Intuitively, the data must be interpretable by the verifier.
In other words, the verifier must be able to derive a decision about the trustworthiness of the prover based on the attestation data.
Our system ensures that by propagating the TCIs as part of the publicly specified TCB Info Evidence extension.
Also, the TCIs constitute of a hash, and the identifier of the used hash algorithm.
Both are well-known concepts easily understandable for a verifier.

\paragraph{Attributable}
It must be possible to assign the attestation data to a specific device, i.e., it must be verifiable that the attestation data originates from the prover.
This is solved by the higher level protocol as well, since such protocols usually involve signing of attestation data, usually a quote.
The quote must be signed with the private EK corresponding to the public key in the EKcert, i.e., the leaf of the certificate chain.
And this private EK can only be created by a device that has the TCIs represented by the previously obtained certificate chain and the according UDS, which is secret and unique for the respective prover.


% \section{Higher level protocols' compatibility}
% Part of related work

\section{Implications of openly propagating system state}

% See: https://www.rfc-editor.org/rfc/rfc9334.html#section-11
An attacker could use the TCIs to find the exact version of the running software and match this to known vulnerabilities~\cite{rfc9334}.

To counteract this, the certificate chain can be transferred from the prover to the verifier via TCP/TLS, which guarantees the confidentiality of the TCI part of the certificates from eavesdroppers.
However, a malicious verifier could initiate the entire attestation process, which is then the TLS endpoint that receives the certificates.
This can be circumvented by authenticating the verifier.
However, this means that the verifier only shares its state with certain verifiers.
This is a trade-off that must be weighed up by the implementers of our solution.


\section{Hardware knowledge dependency}
% Or hardware-agnostic?

% Comparison to RATS architecture
% For RATS: Our system would be integrated by the verifier to establish trust into the fTPM, the relying party wouldn't need to know about it
% For us: verifier = relying party: full burden, needs to know everything
% but required for a (mostly) independent attestation.
% Otherwise trust relationship between verifier and relying party required
% See also Introduction of https://dl.acm.org/doi/10.1145/3600160.3600171

% See abstract of https://www.ietf.org/archive/id/draft-birkholz-rats-corim-01.html

\section{Hardware requirements DICE + fTPM vs TPM}

% Does it even make sense? (Price wise, maybe energy wise)

\section{Retrieve trustworthy TCIs}

It boils down to whether the verifier can ensure that a specific component does not contain any relevant security holes.
In an ideal scenario, the software manufacturers publicize the TCIs of their software which are considered as secure.
However, as of today, this is not common practice.
% The resulting pool might not be that huge, since there is only a tight spectrum of software fulfilling the purposes of boot firmware.

\subsection{Closed source vs.\ Open source}

We expect the verifier to rely on external sources to collect its pool of trustworthy TCIs.
The most prominent example is the observation of CVEs to see if specific versions of a software contain relevant security issues.
For open source software, the verifier has the possibility to derive a security policy based on the source code.

Also, generally speaking, open source software receives more security audits, revealing security holes faster.
With closed source firmware, the verifier is restricted to reverse-engineering (not necessarily doing that itself, e.g., it could also be done by security researchers), or relying on the developer to reliably publicize CVE's about its product.

Usually, this is easier for open source software, which is not a requirement, however.

% The reference values have to come from somebody. Huge burden to the verifier, see paper of Simon for potential improvement

\section{Personal opinion about developed system}

% Maybe too complex?
% Bad feeling about this?
% Benefit bigger than effort?

% https://dl.acm.org/doi/pdf/10.1145/2897937.2898083
% Problems of the prover not being authenticated. This needs to be solved on top of our solution.