% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Related Work}\label{chapter:related_work}

In this chapter we provide a collection of scientific work that relates to this thesis.
For each, we provide a brief overview and how they are connected to our work.

\section{Attacks on TPMs}

Generally, attacks on \acp{TPM} target one of two goals.
Either to reveal secrets stored on the TPM, or to decouple the host system's actual state and the state measured by the \ac{TPM}\@.
From now on, the latter will be referred to as \emph{state decoupling}.


% Attacks on \acp{dTPM} are relevant as they motivate \acp{fTPM}.
% We also introduce attacks on \acp{fTPM} to show that updates and measuring the exact version of them are important to understand which known vulnerabilities are patched and which are not.

% \subsection{\Acl{dTPM}}

\paragraph{\Acl{dTPM}}

The \emph{TPM Reset Attack} on TPM~1.1 is described independently in~\cite{kauerBernhard,sparks2007} conducting state decoupling.
It requires minimal hardware, precisely only a wire connecting the reset line of the LPC bus~\cite{lpc} to ground.
The TPM understands this as a reset signal, yielding predictable values for the \ac{PCR} registers.
This allows an attacker to perform a boot process with malicious components, later resetting the \ac{PCR} values to a known value with the reset attack, and then replay the measurements of a benign boot process.
This not only spoofs the attestation process, but also allows the attacker to access secrets stored on the TPM, which is sealed to the benign state of the host machine.
\Ac{TCG} mitigated this problem by introducing localities with TPM~1.2 which restrict the extension of specific \acp{PCR} to special hardware modes that are no longer accessible in the later boot process~\cite{Proskurin2016}.

Winter and Dietrich~\cite{Winter2013} circumvent this counter measurement with an attack on \acp{dTPM} integrated with the LPC bus or the I\textsuperscript{2}C bus.
Their method---labeled \emph{Active LPC frame hijacking}---allows them to ``lift'' commands to a higher locality than the one they were originally sent with.
% This allows them to evolve the \emph{TPM Reset Attack} from being only usable for \ac{SRTM}, to also \ac{DRTM} systems.
In addition, they introduce a new approach for state decoupling.
Vice versa to the \emph{TPM Reset Attack}, they reset the main device, e.g., a personal computer, while preventing the TPM from receiving the reset signal.
This keeps the benign measurements stored by the TPM, while the attacker can compromise the newly booting system without being measured.
% While this is conceptually easier since the attacker does not need to know the measurement log since the benign \ac{PCR} values are already in-place, 
However, it requires active manipulation of bus transmissions to shield the \ac{TPM} from the reset signal.
The original work is from 2013 and therefore focuses on TPM~1.2.
Despite only having access to TPM~2.0 emulators in 2014, Winter mentions in his master's thesis that initial tests indicate that these attacks also apply to TPM~2.0~\cite{winterMA2014}.
To the best of our knowledge, this is the only statement done about these attacks for TPM~2.0.

% A passive sniffing attack is shown in~\cite{Kursawe2005AnalyzingTP}.
% It is applicable to TPM~1.1 connected to an LPC bus.
% They observed that the data of some operations like unsealing are transmitted via the bus in plaintext.
% Since TPM~1.2 the modules no longer send sensitive data unencrypted~\cite{Winter2013}.

% That invasive hardware attacks against \acp{dTPM} are possible was already shown by Tarnovsky in 2010~\cite{tarnovsky}.
% Nevertheless, this requires a lot of time, knowledge and resources, i.e., hardware and money.

% \subsection{\Acl{fTPM}}
\paragraph{\Acl{fTPM}}

As seen in the previous section, the bus between the CPU and a \ac{dTPM} is a typical attack vector throughout their history.
An \ac{fTPM} circumvents this by being directly executed by the CPU within a \ac{TEE}, revealing no easily accessible bus.
Nevertheless, there are also attacks against \acp{fTPM}.

Moghimi et al.~\cite{Moghimi2019} demonstrate a time-based side-channel attack.
It applies to Intel's \ac{fTPM} before the corresponding software patch in November 2019, and allows an attacker to recover 256-bit private keys for ECDSA and ECSchnorr signatures.
% STM published a solution, but this involves a hardware update and not just a software update.

Seunghun Han et al.~\cite{aBadDream} report two further state decoupling attacks.
The first targets a gray area in the power management section of the TPM~2.0 specification.
If the host platform goes into sleep mode, it can send a command to the \ac{TPM} demanding it to store its current state including its \acp{PCR} in its non-volatile RAM\@.
When the host platform wakes up again, it can request that the saved state be restored with a corresponding command.
Yet, the specification lacks a concrete description of the behavior if the \ac{TPM} has not saved any state before going to sleep, but still receives the command to restore its saved state when waking up.
It merely states that the \ac{TPM} implementation is expected ``to take corrective action'' which also applies to the latest version of the \ac{TPM} specification at the time of writing~\cite{tpm20}.
Hence, some implementations simply reset the \ac{TPM} which resets its \acp{PCR}.
Software updates from the manufacturers are required to close this vulnerability in their implementation.
Their second attack targets an \ac{fTPM} running with Intel's Trusted Execution Technology.
They exploit that some mutable function pointers are not measured in its measuring boot environment allowing arbitrary code execution.
Thereby, the \acp{PCR} can be reset.
The authors fixed this issue upstream with a software patch.

Jacob et al.~\cite{Jacob2023} target proprietary AMD fTPMs by attacking their \ac{TEE}, namely the AMD Secure Processor~(AMD-SP).
By that, they can expose the full internal state of the \ac{fTPM} bypassing any authentication mechanisms.
To do so, they leak the secret key from the BIOS flash chip which is used to derive the encryption and signature keys for the \acp{fTPM} non-volatile data.
They achieve this by using a voltage fault injection that bypasses the authenticity check in the host's boot process and allows them to boot their own firmware component that leaks the required information.

Cohen from the Google Cloud Security team also targets AMD's fTPM running with the AMD-SP~\cite{cohen}.
They store a maliciously crafted payload---a certificate---on the \ac{fTPM} and trigger a function with a stack-based overflow error that accesses this payload, giving them full control over the program counter.
According to the author, this bug is limited to vendors that diverge from the \ac{TPM} specification, as this issue does not appear in \ac{TCG}'s reference code.
AMD resolves this issue with a software patch.

These attacks on \acp{fTPM} show that they need to be updatable to respond to the disclosure of future vulnerabilities.
They should also be measured to understand which known vulnerabilities are patched and which are not.

\section{Hardening of TPMs}

In the following, we describe defense mechanisms for fTPMs that can be seen as complementary to our approach.
They all have in common that they offer no way for a third party to ensure that the hardened fTPM is actually running on the device under test, which is exactly what our work aims to cover.

\subsection{Firmware TPMs}

One approach is to formally verify the code of fTPMs towards specific security properties.
Mukhamedov et al.~\cite{Mukhamedov2013} write portions of the TPM~1.2 code in a functional programming language---namely F\texttt{\#}---that enables automatic verification.

Raj et al.~\cite{Raj2015} call for hardware entropy for a secure \ac{fTPM} implementation, but do not elaborate on how this can be achieved.
Kim and Kim~\cite{Kim2019} propose an abstraction layer on top of an \ac{fTPM} and a \ac{dTPM}---the hybrid TPM~(hTPM), which enables switching between the hardware and software module as required.
They aim to combine their advantages, e.g., by making the dTPM the source for the hardware entropy of the fTPM\@.
In addition, the hTPM performs significantly better in software mode than in hardware mode due to the use of modern CPU features.
But for all that this comes at the cost of increasing complexity.

In contrast, Gross et al.~\cite{Gross2021} propose backing an \ac{fTPM} with hardware without requiring a \ac{dTPM}.
For that, they provide cryptographic and entropy support through hardware.
This inherits the downsides of \acp{fTPM} which are not related to a lack of hardware, but to the nature of software.
For example, their \ac{fTPM} is still started later in the boot chain than a \ac{dTPM}, which is not the case for an hTPM\@.
Despite that, it is easier to update than hTPM since the lack of a dTPM, and the overall design is simpler.

\subsection{Virtual TPMs}

% Due to the increasing popularity of cloud computing, the research of vTPMs focuses less on specific attacks, and more on reducing the trusted computing base, i.e., privacy-focused.
The initially proposed design of virtual \acp{TPM} requires the operating system and the hypervisor to be trusted~\cite{268868}.

Wang et al.~\cite{Wang2019} bring the vTPM into the \ac{TEE}, namely Intel SGX, essentially creating an fTPM and vTPM hybrid.
They launch each vTPM in a private hardware-protected enclave.
This reduces the required trust into to the individual enclaves and SGX itself, enabling the host operating system and hypervisor to be untrusted.

Pecholt and Wessel~\cite{Pecholt2022} describe a design named CoCoTPM where the hypervisor and the host's operating system do not need to be trusted as well.
This is realized by establishing an integrity-protected secure channel with end-to-end encryption between the driver in the VM and the software TPM on the host.

Stateless ephemeral vTPMs~\cite{Narayanan2023} eliminate the need of manually establishing a secure channel by leveraging the confidential VM memory encryption provided by AMD's SEV-SNP, a variant of AMD secure encrypted virtualization~(SEV) technology.
Ephemeral vTPMs support the remote attestation of virtual machines.
On the other hand, they intentionally do not support persistent storage to preclude exfiltration attacks on the TPM's data-at-rest, which has the disadvantage that persistent keys or nonvolatile indexes cannot be stored.

\section{Remote attestation schemes}

% Other defense concepts

% Linux attested with DICE directly instead of TPM?
% Probable disadvantage: not TPMs common interfaces
% and DICE certificate chain size grows linearly, PCR register size is fixed. However, event log also grows linearly, but less data (less information, but less storage overhead)

% https://www.eurecom.fr/fr/publication/3536/download/rs-publi-3536.pdf
The SMART attestation mechanism proposed by Defrawy et al.~\cite{EURECOM+3536} establishes a \ac{DRTM}.
Since their overall approach is similar to \ac{DICE}, they only hardware requirement is a ROM containing a key (corresponding to DICE's \ac{UDS}), and that can only be accessed by SMART\@.
Their secret key is directly used to sign attestation data, while for \ac{DICE} the \ac{UDS} acts as entropy to derive individual secrets from for each firmware component.
SMART thus provides a \ac{DRTM} in contrast to the \ac{SRTM} provided by \ac{DICE} enabling the remote attestation of an \ac{fTPM}.
However, it does not allow data to be bound to the identity of a firmware component.

\ac{TCG} offers an adaption of \ac{DICE} with symmetric cryptography which conducts implicit attestation~\cite{dice-symmetric-arch}.
There, the final symmetric key---also called alias key here---derived from the compound identity of the whole firmware and its UDS represent the prover's identity, without propagating the individual identities of each firmware layer like the \acp{TCI} do.
If this alias key is leaked, trust into the system breaks unrecoverable since the same key is generated on each boot.
DICE+ proposed by Jia et al.~\cite{Jia2020} solves this by equipping the prover with a monotonic counter, which is incremented on each reboot.
This counter influences the alias key, which consequently alters the attestation result derived from it after each reboot as well.
The verifier can calculate the expected attestation data by combining the used counter value, the UDS, and the expected firmware identity.
DICE+ assumes that there is only a single verifier who knows the received values of all previously conducted remote attestations, and can therefore detect replay attacks.
The verifier and the prover must have shared secrets due to the nature of attestation based on symmetric cryptography.
DICE+ shares the prover's UDS and also the initial monotonic counter with the verifier during the prover's provisioning in an out-of-band manner.
While their approach is practical for low-end devices that are not capable of asymmetric cryptography, we are targeting machines with a processor with a \ac{TEE}, which implies a certain amount of computation power.
We also do not want to require pre-shared secrets between the verifier and the prover.
In addition, the TPM's infrastructure demands asymmetric cryptography for signing the EK certificate, and the monotonic counter would change the TPM's identity on each reboot, effectively hindering the binding of the fTPM's data to its identity.
Hence, we use DICE with asymmetric cryptography instead.

% They claim it is implicit, but I believe they have another understanding of implicit and explicit as what I use in this thesis (the one from the DICE spec). So I just leave it, as it is only confusing and not of great importance.
Bravi, Sisinni, and Lioy~\cite{Bravi2023} propose an attestation system with DICE for IoT devices running with the RISC-V ISA without TEE\@.
While we combine DICE with the TPM infrastructure, they combine it with the Manufacturer Usage Description (MUD).
MUD allows a device to signal to the network what kind of access and network functionality it requires for further access control~\cite{Lear2019}.
It also explains how DICE can be implemented with the novel RISC-V technology Physical Memory Protection~(PMP).
Their design is orthogonal to ours, and they are compatible.
This is because we are not limited to a specific DICE implementation and their support for MUD is integrated via an X.509 certificate extension that can trivially be added to our system as well.

\section{DICE implementation}

Jäger, Petri, and Fuchs~\cite{Jaeger2017} describe how the remote attestation procedure described in the DICE specification can be put into practice by discussing implementation options.
Thereby they complement our work by evaluating how to implement \ac{DICE}\@.
Jäger and Petri continue their work later~\cite{Jaeger2020} because they observed a limitation in their initial implementation, allowing to jump into \ac{DICE} code possibly leaking the \ac{UDS}.
Lorych and Jäger carried on exploring the design space of DICE~\cite{Lorych2022} later on.
As with SMART, the goal of all these publications is not to attest an \ac{fTPM} and therefore do not describe how to combine the infrastructure of DICE and \acp{fTPM}.

Just as we presented a paper proposing a formally verified \ac{fTPM} implementation, Tao et al.~\cite{272306} propose a formally verified \ac{DICE} implementation called DICE\( ^* \).
They focus on the software side of the first DICE layer and are agnostic to the actual hardware used.
Therefore, it can be used together with the hardware designs from the previously listed works.

% TEE attestation

% M{\'{e}}n{\'{e}}trey et al.~\cite{Menetrey2022} discuss attestation mechanisms for \acp{TEE}.
% Our \ac{fTPM} is also running in a \ac{TEE}, and can thereby be attested with this approach.
% However, it assumes that the entire TEE is trusted


% Attacks which we would avoid (e.g., exchange/spoof EKcert)


% https://dl.acm.org/doi/pdf/10.1145/3600160.3600171
% This requires trusting the measurement root of trust (there TPM, AMD SEV-SNP or Arm PSA Attestation Token), but also need to trust the operator to provide benign reference values.
% Or not if the operator of the trust anchor is the same as the operator of the device. Or the trust anchor and the reference values root in the operator. Operator needs to sign (and beforehand verify) not only the trust anchor, but also reference values (high burden).
% The paper also only mentions hardware trust anchors, no fTPMs. Could be used in conjunction. I believe our cert chain up to the fTPM would need to be provided within the Attestation Report, but system independent, i.e., would need to be independent of the concrete technology (here DICE). Not sure if that's possible.

% https://www.amd.com/en/processors/amd-secure-encrypted-virtualization
% For virtual machines
% Auch https://arxiv.org/pdf/2204.06790.pdf
% 3.5

% https://ieeexplore.ieee.org/abstract/document/9292371

% https://netsec.ethz.ch/publications/papers/mccune_parno_perrig_reiter_isozaki_eurosys08.pdf
