% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Related Work}\label{chapter:related_work}

\section{Attacks on TPMs}

\subsection{Dedicated TPM}

The well-known `TPM Reset Attack' on TPM~1.1 was described independently in~\cite{kauerBernhard,sparks2007}, whereby the state of the host computer and the TPM are decoupled.
It requires minimal hardware, precisely only a wire connecting the reset line of the LPC bus~\cite{lpc} to ground.
The TPM understands this as a reset signal, yielding predictable values for the \ac{PCR} registers.
This allows an attacker perform a boot process with malicious components, later resetting the \ac{PCR} values to a known value with the reset attack, and then replay the measurements of a benign boot process.
This not only spoofs the attestation process, but also allows the attacker to access secrets stored on the TPM, which is sealed to the benign state of the host machine.
\ac{TCG} mitigated this problem by introducing localities with TPM~1.2 by restricting the extension of specific \acp{PCR} to special hardware modes that are no longer accessible in the later boot process~\cite{tpmResetMitigation}.

Winter and Dietrich~\cite{Winter2013} demonstrate a bus modification attack at TPMs integrated with the LPC bus or the I\textsuperscript{2}C bus.
Their approach---labeled `Active LPC frame hijacking'---allows them to ``lift'' commands to a higher locality than the one they were originally sent with.
This allows them to evolve the `TPM Reset attack' from being only usable for \ac{SRTM}, to also \ac{DRTM} systems.
They also introduce a new approach of circumventing the TPM's measurement feature.
Instead of resetting the TPM as previously described~\cite{kauerBernhard,sparks2007}, they reset the main device, e.g., a PC, while preventing the TPM from receiving the reset signal.
This keeps the state of the TPM, i.e., the \ac{PCR} values of the previous benign boot procedure, and the attacker can hijack the boot procedure triggered by the platform's reset and boot a malicious operating system or firmware, while the TPM still stores the old and benign PCRs.
While its conceptually easier since the attacker does not need to know the measurement log since the benign \ac{PCR} values are already in-place, it requires active manipulation of bus transmissions to shield the TPM from the reset signal.

Seunghun Han et al.~\cite{aBadDream} report two attacks on discrete TPMs to reset the PCR registers.
The first targets a gray area in the power management section of the TPM~2.0 specification.
If the host platform goes into sleep mode, it can send a command to the TPM demanding it to store its current state including its PCRs in its non-volatile random access memory (NVRAM).
When the host platform wakes up again, it can request that the saved state be restored with a corresponding command.
However, the specification lacks a concrete description of the behavior if the TPM has not saved any state before going to sleep, but still receives the command to restore its ``saved'' state when waking up.
It merely states that the TPM implementation is expected ``to take corrective action''.
Hence, some implementations simply reset the TPM which resets the \acp{PCR} as well.
This also applies to the latest version of the TPM specification at the time of writing~\cite{tpm20}.
Their second attack targets a \ac{DRTM}, namely an implementation flaw in tboot\footnote{\url{https://www.sourceforge.net/projects/tboot}}, a widely used measured boot environment used with Intel's Trusted Execution Technology.
They found that some mutable function pointers are not measured, which enables attacks.

A time-based side-channel attack~\cite{Moghimi2019} during signature generation based on elliptic curves allows an attacker to recover 256-bit private keys for ECDSA and ECSchnorr signatures.

A passive sniffing attack is shown in~\cite{Kursawe2005AnalyzingTP}.
It is applicable to TPM 1.1 connected to an LPC bus.
They observed that the data of some operations like unsealing are transmitted via the bus in plaintext.
Since TPM 1.2, however, the modules no longer send sensitive data unencrypted~\cite{Winter2013}.

That invasive hardware attacks against \acp{dTPM} are possible was already shown by Tarnovsky in 2010~\cite{tarnovsky}.
However, this requires a lot of time, knowledge and resources, i.e., hardware and money.

\subsection{Firmware TPM}

As seen in the previous section about discrete TPMs, the bus between the CPU and a TPM is a typical attack vector.
An \ac{fTPM} circumvents this by being directly executed by the CPU within a \ac{TEE}, revealing no easily accessible bus.

However, there are also attacks against \acp{fTPM}.
The previously mentioned side-channel attack~\cite{Moghimi2019} against \acp{dTPM} can also be applied to \acp{fTPM}.

Jacob et al.~\cite{Jacob2023} target proprietary AMD fTPMs by attacking their \ac{TEE}, namely the AMD Secure Processor~(AMD-SP).
Thereby, they can expose the full internal state of the \ac{fTPM} bypassing any authentication mechanisms.
To do so, they leak the secret key from the BIOS flash chip which is used to derive the encryption and signature keys for the \acp{fTPM} non-volatile data.
They achieve this by using a voltage fault injection that bypasses the authenticity check in the host's boot process and allows them to boot their own firmware component that leaks the required information.

Cfir Cohen from the Google Cloud Security team also targets AMD's fTPM running AMD-SP (formerly known as AMD-PSP)~\cite{cohen}.
They store a maliciously crafted payload---a certificate---on the \ac{fTPM} and trigger a function with a stack-based overflow error that accesses this payload, giving them full control over the program counter.
However, this bug seems to be limited to AMD's fTPM implementation and does not appear in TCG's reference code.

\section{Hardening of TPMs}

In the following, we describe defense mechanisms for fTPMs that can be seen as complementary to our approach.
They all have in common that they offer no way for a third party to ensure that the hardened fTPM is actually running on the device under test, which is exactly what our work aims to cover.

\subsection{Firmware TPMs}

One approach is to formally verify the code of fTPMs towards specific security properties.
Mukhamedov et al.~\cite{Mukhamedov2013} write portions of the TPM~1.2 code in a functional programming language---namely F\texttt{\#}---that enables automatic verification.

Raj et al.~\cite{Raj2015} call for hardware entropy for a secure \ac{fTPM} implementation, but do not elaborate on how this can be achieved.
Kim and Kim~\cite{Kim2019} propose an abstraction layer on top of a \ac{fTPM} and a \ac{dTPM}---the hybrid TPM~(hTPM).
It makes it possible to switch between the hardware and software solution as required.
They use the hTPM to combine the advantages of an \ac{fTPM} and a \ac{dTPM}, e.g., by making the dTPM the source for the hardware entropy of the fTPM\@.
In addition, the hTPM performs significantly better in software mode than in hardware mode due to the use of modern CPU features.
However, all this comes at the cost of increasing complexity.

In contrast, Gross et al.~\cite{Gross2021} propose backing an \ac{fTPM} with hardware without requiring a \ac{dTPM}.
For that, they provide cryptographic and entropy support through hardware.
However, their implementation inherits the downsides of \acp{fTPM} which are not related to their hardware support, but to their software nature.
For example, their \ac{fTPM} is still started later in the boot chain than a \ac{dTPM}, which is not the case for hTPM\@.
However, it is easier to update than hTPM since the lack of a dTPM, and the overall design is simpler.

\subsection{Virtual TPMs}

Because of the increasing popularity of cloud computing, the research of vTPMs focuses less on specific attacks, and more on reducing the trusted computing base, i.e., privacy-focused.
The initially proposed design~\cite{268868} has a large trusted base, e.g., the operating system and the hypervisor need to be trusted.

Wang et al.~\cite{Wang2019} bring the vTPM into the \ac{TEE}, namely Intel SGX, essentially creating an fTPM and vTPM hybrid.
They launch each vTPM in a private hardware-protected enclave.
This reduces the trusted computing base to the individual enclaves and SGX itself, enabling the host operating system and hypervisor to be untrusted.

Pecholt and Wessel~\cite{Pecholt2022} describe a design named CoCoTPM where the hypervisor and the host's operating system do not need to be trusted as well.
This is realized by establishing an integrity-protected secure channel with end-to-end encryption between the driver in the VM and the software TPM on the host.

Stateless ephemeral vTPMs~\cite{Narayanan2023} eliminate the need of manually establishing a secure channel by leveraging the confidential VM memory encryption provided by AMD's SEV-SNP, a variant of AMD secure encrypted virtualization~(SEV) technology.
Ephemeral vTPMs support the remote attestation of virtual machines.
However, they intentionally do not support persistent storage to preclude exfiltration attacks on stored TPM state, which has the disadvantage that persistent keys or nonvolatile indexes cannot be stored.

\section{Attestation schemes of TPMs}

% Other defense concepts

% Linux attested with DICE directly instead of TPM?
% Probable disadvantage: not TPMs common interfaces
% and DICE certificate chain size grows linearly, PCR register size is fixed. However, event log also grows linearly, but less data (less information, but less storage overhead)

% https://www.eurecom.fr/fr/publication/3536/download/rs-publi-3536.pdf
The SMART attestation mechanism proposed by Defrawy et al.~\cite{EURECOM+3536} establishes a \ac{DRTM} with little hardware requirements.
In fact, their hardware requirements and overall approach are similar to \ac{DICE}, i.e., they require a ROM containing a key (corresponding to DICE's \ac{UDS}), and that can only be accessed by SMART\@.
Their secret key is directly used to sign attestation data, while for \ac{DICE} the \ac{UDS} acts as entropy to derive individual secrets from for each firmware component.
This allows SMART to establish a \ac{DRTM}, in contrast to the \ac{SRTM} provided by \ac{DICE}.
However, sealing data to the identity of a firmware component is not possible with SMART\@.
Hence, while the sole remote attestation of an \ac{fTPM} is enabled with SMART, it cannot bind the fTPM's storage to the fTPM's identity.

% DICE implementation

Jäger, Petri, and Fuchs~\cite{Jaeger2017} describe how the remote attestation procedure described in the DICE specification can be put into practice by discussing implementation options.
However, they complement our work by evaluating how to implement \ac{DICE}\@.
Jäger and Petri continue their work later~\cite{Jaeger2020} because they observed a limitation in their initial implementation, allowing to jump into \ac{DICE} code possibly leaking the \ac{UDS}.
Lorych and Jäger carried on exploring the design space of DICE~\cite{Lorych2022} later on.
As with SMART, the goal of all these publications is not to attest an \ac{fTPM} and therefore do not describe how to combine the infrastructure of DICE and \acp{fTPM}.

Bravi, Sisinni, and Lioy~\cite{Bravi2023} propose an implicit attestation system with DICE for IoT devices running with the RISC-V ISA without TEE\@.
While we combine DICE with the TPM infrastructure, they combine it with the Manufacturer Usage Description (MUD).
MUD allows a device to signal to the network what kind of access and network functionality it requires for further access control~\cite{Lear2019}.
It also explains how DICE can be implemented with the novel RISC-V technology Physical Memory Protection~(PMP).
Their design is orthogonal to ours, and they are compatible.
This is because we are not limited to a specific DICE implementation and their support for MUD is integrated via an X.509 certificate extension that can trivially be added to our system as well.

% TEE attestation

% M{\'{e}}n{\'{e}}trey et al.~\cite{Menetrey2022} discuss attestation mechanisms for \acp{TEE}.
% Our \ac{fTPM} is also running in a \ac{TEE}, and can thereby be attested with this approach.
% However, it assumes that the entire TEE is trusted


% Attacks which we would avoid (e.g., exchange/spoof EKcert)


% https://dl.acm.org/doi/pdf/10.1145/3600160.3600171
% This requires trusting the measurement root of trust (there TPM, AMD SEV-SNP or Arm PSA Attestation Token), but also need to trust the operator to provide benign reference values.
% Or not if the operator of the trust anchor is the same as the operator of the device. Or the trust anchor and the reference values root in the operator. Operator needs to sign (and beforehand verify) not only the trust anchor, but also reference values (high burden).
% The paper also only mentions hardware trust anchors, no fTPMs. Could be used in conjunction. I believe our cert chain up to the fTPM would need to be provided within the Attestation Report, but system independent, i.e., would need to be independent of the concrete technology (here DICE). Not sure if that's possible.

% https://www.amd.com/en/processors/amd-secure-encrypted-virtualization
% For virtual machines
% Auch https://arxiv.org/pdf/2204.06790.pdf
% 3.5

% https://ieeexplore.ieee.org/abstract/document/9292371

% https://netsec.ethz.ch/publications/papers/mccune_parno_perrig_reiter_isozaki_eurosys08.pdf
